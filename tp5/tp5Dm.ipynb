{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification et regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite pour K=3: bench\n",
      "Classe prédite pour K=10: bench\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import mstats\n",
    "from collections import Counter\n",
    "\n",
    "# Étape 1 Lecture et prétraitement du dataset\n",
    "def load_and_preprocess_dataset(file_path):\n",
    "    # Lecture du fichier \n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # Suppression des valeurs manquantes\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Conversion des colonnes numériques en float\n",
    "    numeric_columns = ['Acc_x', 'Acc_y', 'Acc_z', 'Gyro_x', 'Gyro_y', 'Gyro_z']\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Suppression des nouvelles valeurs manquantes après conversion\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Gestion des outliers avec winsorisation\n",
    "    for col in numeric_columns:\n",
    "        df[col] = mstats.winsorize(df[col], limits=[0.05, 0.05])  # 5% winsorization\n",
    "\n",
    "    # Discrétisation des valeurs et remplacement par la moyenne de chaque intervalle\n",
    "    for col in numeric_columns:\n",
    "        bins = np.linspace(df[col].min(), df[col].max(), 5)  # 4 intervalles\n",
    "        labels = [(bins[i] + bins[i+1]) / 2 for i in range(len(bins) - 1)]\n",
    "        df[col] = pd.cut(df[col], bins=bins, labels=labels).astype(float)\n",
    "    \n",
    "    # Normalisation des données numériques\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "# Étape 2: Calcul de la distance entre deux instances (Manhattan + Hamming)\n",
    "def calculate_distance(instance1, instance2, categorical_columns, numeric_columns):\n",
    "    distance = 0.0\n",
    "    \n",
    "    # Distance Manhattan pour les colonnes numériques\n",
    "    for col in numeric_columns:\n",
    "        distance += abs(instance1[col] - instance2[col])\n",
    "    \n",
    "    # Distance de Hamming pour les colonnes catégoriques\n",
    "    for col in categorical_columns:\n",
    "        if instance1[col] != instance2[col]:\n",
    "            distance += 1\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Étape 3: Trier les instances selon la distance\n",
    "def sort_by_distance(dataset, target_instance, categorical_columns, numeric_columns):\n",
    "    distances = []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        dist = calculate_distance(row, target_instance, categorical_columns, numeric_columns)\n",
    "        distances.append((row, dist))\n",
    "    \n",
    "    # Trier par distance croissante\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return [item[0] for item in distances]\n",
    "\n",
    "# Étape 4: Trouver la classe dominante parmi les k voisins\n",
    "def get_dominant_class(neighbors, class_column):\n",
    "    classes = [neighbor[class_column] for neighbor in neighbors]\n",
    "    return Counter(classes).most_common(1)[0][0]\n",
    "\n",
    "# Étape 5: Implémentation de l'algorithme k-NN\n",
    "def knn(dataset, target_instance, k, categorical_columns, numeric_columns, class_column):\n",
    "    # Retirer 'Label' des colonnes catégoriques\n",
    "    if class_column in categorical_columns:\n",
    "        categorical_columns.remove(class_column)\n",
    "    \n",
    "    sorted_instances = sort_by_distance(dataset, target_instance, categorical_columns, numeric_columns)\n",
    "    k_neighbors = sorted_instances[:k]\n",
    "    return get_dominant_class(k_neighbors, class_column)\n",
    "\n",
    "# Charger et prétraiter le dataset\n",
    "file_path = \"DatasetExos.csv\"  # Remplacez par le chemin réel de votre fichier\n",
    "df = load_and_preprocess_dataset(file_path)\n",
    "\n",
    "# Définir les colonnes pour le calcul des distances\n",
    "categorical_columns = ['ID', 'Label', 'Category', 'Set']\n",
    "numeric_columns = ['Acc_x', 'Acc_y', 'Acc_z', 'Gyro_x', 'Gyro_y', 'Gyro_z']\n",
    "class_column = 'Label'\n",
    "\n",
    "# Instance cible\n",
    "target_instance = {\n",
    "    'Acc_x': -0.137, 'Acc_y': 1.066, 'Acc_z': 0.8215,\n",
    "    'Gyro_x': -6.597, 'Gyro_y': 0.808, 'Gyro_z': 1.985,\n",
    "    'ID': 'B', 'Category': 'medium', 'Set': 30\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\" target_instance = {\n",
    "    'Acc_x': -0.0545,\n",
    "    'Acc_y': 0.545,\n",
    "    'Acc_z': 0.896,\n",
    "    'Gyro_x': -0.8413999999999998,\n",
    "    'Gyro_y': 0.8538,\n",
    "    'Gyro_z': 18.778, \n",
    "    'ID': 'A',\n",
    "    'Category': 'heavy',\n",
    "    'Set': 22\n",
    "}  \"\"\"\n",
    "\n",
    "\n",
    "def normalize_target_instance(target_instance, df, numeric_columns):\n",
    "    \"\"\"\n",
    "    Normalise l'instance cible en utilisant les min et max des colonnes numériques du dataset initial.\n",
    "    \n",
    "    Parameters:\n",
    "        target_instance (dict): Instance cible à normaliser.\n",
    "        df (DataFrame): Dataset contenant les valeurs min et max des colonnes numériques.\n",
    "        numeric_columns (list): Liste des colonnes numériques à normaliser.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Instance cible normalisée.\n",
    "    \"\"\"\n",
    "    # Extraire les min et max des colonnes numériques du dataset initial\n",
    "    min_values = df[numeric_columns].min()\n",
    "    max_values = df[numeric_columns].max()\n",
    "    \n",
    "    # Appliquer la normalisation Min-Max\n",
    "    for col in numeric_columns:\n",
    "        target_instance[col] = (target_instance[col] - min_values[col]) / (max_values[col] - min_values[col])\n",
    "    \n",
    "    return target_instance\n",
    "\n",
    "\n",
    "def discretize_target_instance(target_instance, df, numeric_columns):\n",
    "    for col in numeric_columns:\n",
    "        bins = np.linspace(df[col].min(), df[col].max(), 5)  # Même nombre d'intervalles\n",
    "        labels = [(bins[i] + bins[i+1]) / 2 for i in range(len(bins) - 1)]\n",
    "        target_instance[col] = pd.cut([target_instance[col]], bins=bins, labels=labels).astype(float)[0]\n",
    "    return target_instance\n",
    "\n",
    "\n",
    "\n",
    "# Normaliser la target_instance avant de prédire\n",
    "target_instance = normalize_target_instance(target_instance, df, numeric_columns)\n",
    "\"\"\" # Discrétisation de l'instance cible\n",
    "target_instance = discretize_target_instance(target_instance, df, numeric_columns) \"\"\"\n",
    "\n",
    "\n",
    "# Appliquer k-NN pour K = 3 et K = 10\n",
    "for k in [3, 10]:\n",
    "    predicted_class = knn(df, target_instance, k, categorical_columns, numeric_columns, class_column)\n",
    "    print(f\"Classe prédite pour K={k}: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
